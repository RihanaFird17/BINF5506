Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job                  count
-----------------  -------
all                      1
annotate_variants        1
call_variants            1
filter_variants          1
index_bam                1
mark_duplicates          1
upload_s3                1
total                    7

Select jobs to execute...

[Thu Mar 27 04:02:36 2025]
rule mark_duplicates:
    input: results/snakemake/.dirs_created, results/aligned/aligned.sorted.bam
    output: results/aligned/dedup.bam
    jobid: 8
    reason: Missing output files: results/aligned/dedup.bam
    resources: tmpdir=/tmp

[Thu Mar 27 04:02:39 2025]
Error in rule mark_duplicates:
    jobid: 8
    input: results/snakemake/.dirs_created, results/aligned/aligned.sorted.bam
    output: results/aligned/dedup.bam
    shell:
        
        echo Marking duplicates...
        gatk MarkDuplicates -I results/aligned/aligned.sorted.bam -O results/aligned/dedup.bam -M results/aligned/dup_metrics.txt
        echo Marked duplicates!
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2025-03-27T040235.907725.snakemake.log
